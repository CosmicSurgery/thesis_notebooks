{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8af4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate\n",
    "np. set_printoptions(threshold=np. inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8acced35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sept27th-scan_stats_SPADE.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = 'Sept27th-'\n",
    "filename = ''.join((date,'scan_stats_SPADE.json'))\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963746c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scan\n",
    "import simulate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4be0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'M':8,\n",
    "    'N':40,\n",
    "    'D':51,\n",
    "    'T':1000,\n",
    "    'seed':0,\n",
    "    'num_SM_events':16,\n",
    "    'SM_total_spikes':10,\n",
    "    'noise':100\n",
    "}\n",
    "scan_dict = {\n",
    "    'M':[1,4,8,16,32],\n",
    "    'N':[10,20,40,80,120],\n",
    "    'D':[11,31,51,71,101],\n",
    "    'num_SM_events':[2,4,8,16,32],\n",
    "    'SM_total_spikes':[3,5,10,20,50],\n",
    "    'noise':[0,50,100,500,1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf37a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(matrix_x,matrix_y):\n",
    "    # Calculate cross-correlation matrix\n",
    "    cc = np.zeros((matrix_x.shape[2], matrix_y.shape[2]))\n",
    "\n",
    "    for x_channel_idx in range(matrix_x.shape[2]):\n",
    "        for y_channel_idx in range(matrix_y.shape[2]):\n",
    "            cc[x_channel_idx, y_channel_idx], _ = max_overlap(matrix_x[...,x_channel_idx],matrix_y[...,y_channel_idx])\n",
    "    SM_acc = np.max(cc,axis=1)\n",
    "    return SM_acc, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd802d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_overlap(image, kernel):\n",
    "    result = np.zeros((image.shape[1]+kernel.shape[1]-1))\n",
    "    for n in range(image.shape[0]):\n",
    "        result += correlate(image[n,:], kernel[n,:], mode = 'full')\n",
    "    return np.max(result)/max(np.sum(image),np.sum(kernel)), np.argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1518e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(K_dense, pattern_template):\n",
    "    if len(pattern_template) == 0:\n",
    "        print('FAIL')\n",
    "        return pattern_template, None\n",
    "    \n",
    "    win_size = (K_dense.shape[0],1+max([max(k[:,0]) for k in pattern_template]))\n",
    "    pattern_img = np.zeros((len(pattern_template),*win_size))\n",
    "    for p,pattern in enumerate(pattern_template):\n",
    "        for (i,j) in pattern:\n",
    "            pattern_img[p,j,i] = 1\n",
    "            \n",
    "    pattern_img = pattern_img.transpose((1,2,0))\n",
    "    \n",
    "    return pattern_template, pattern_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed67c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "def get_acc(ground_truths,detected_patterns):\n",
    "    # Calculate cross-correlation matrix\n",
    "    cross_corr_matrix = np.zeros((ground_truths.shape[2], detected_patterns.shape[2]))\n",
    "    SM_acc = np.zeros((ground_truths.shape[2]))\n",
    "    \n",
    "    if len(detected_patterns) == 0:\n",
    "        return SM_acc, cross_corr_matrix\n",
    "    \n",
    "    for ground_truths_idx in range(ground_truths.shape[2]):\n",
    "        for detected_patterns_idx in range(detected_patterns.shape[2]):\n",
    "            cross_corr = np.zeros((ground_truths.shape[1]+detected_patterns.shape[1]-1))\n",
    "            for n in range(ground_truths.shape[0]):\n",
    "                cross_corr += correlate(ground_truths[n, :, ground_truths_idx], detected_patterns[n, :, detected_patterns_idx], mode='full')\n",
    "            max_corr = np.max(cross_corr) / max(np.sum(ground_truths[...,ground_truths_idx]),np.sum(detected_patterns[...,detected_patterns_idx]))\n",
    "            cross_corr_matrix[ground_truths_idx, detected_patterns_idx] = max_corr\n",
    "#     print(cross_corr_matrix)\n",
    "#     print( np.sum(ground_truths[...,ground_truths_idx]))\n",
    "    SM_acc = np.max(cross_corr_matrix,axis=1)\n",
    "    return SM_acc, cross_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9143fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ground_truth(pattern_template, K_dense):\n",
    "    _, pattern_img = get_imgs(K_dense, pattern_template)\n",
    "    SM_acc, cc = get_acc(K_dense, pattern_img)\n",
    "    return SM_acc, cc, pattern_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a240e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = []\n",
    "for param_name, param_values in scan_dict.items():\n",
    "    for param_value in param_values:\n",
    "        params = default_params.copy()\n",
    "        params[param_name] = param_value\n",
    "        param_combinations.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7847e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "253cf905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special SPADE packages...\n",
    "import quantities as pq\n",
    "import neo\n",
    "import elephant\n",
    "import viziphant\n",
    "from neo.core import SpikeTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55bab883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_spade(patterns, win_size):\n",
    "    spade_patterns = []\n",
    "    for pattern in patterns:\n",
    "        spade_patterns.append(np.array([np.sort(np.array(pattern['itemset'])) % win_size, np.sort(np.array(pattern['neurons']))]).T)\n",
    "    return spade_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d1f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 1, 'N': 40, 'D': 51, 'T': 1000, 'seed': 0, 'num_SM_events': 8, 'SM_total_spikes': 10, 'noise': 100}\n",
      "Time for data mining: 0.08275675773620605\n",
      "{'M': 4, 'N': 40, 'D': 51, 'T': 1000, 'seed': 0, 'num_SM_events': 8, 'SM_total_spikes': 10, 'noise': 100}\n",
      "Time for data mining: 0.2990283966064453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:02,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 8, 'N': 40, 'D': 51, 'T': 1000, 'seed': 0, 'num_SM_events': 8, 'SM_total_spikes': 10, 'noise': 100}\n",
      "Time for data mining: 1.008591651916504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:29, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 16, 'N': 40, 'D': 51, 'T': 1000, 'seed': 0, 'num_SM_events': 8, 'SM_total_spikes': 10, 'noise': 100}\n",
      "Time for data mining: 7.367804288864136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [08:00, 185.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M': 32, 'N': 40, 'D': 51, 'T': 1000, 'seed': 0, 'num_SM_events': 8, 'SM_total_spikes': 10, 'noise': 100}\n",
      "{'M': 8, 'N': 10, 'D': 51, 'T': 1000, 'seed': 0, 'num_SM_events': 8, 'SM_total_spikes': 10, 'noise': 100}\n",
      "Time for data mining: 5.9182703495025635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define default parameters and scan values\n",
    "default_params = {\n",
    "    'M': 8,\n",
    "    'N': 40,\n",
    "    'D': 51,\n",
    "    'T': 1000,\n",
    "    'seed': 0,\n",
    "    'num_SM_events': 8,\n",
    "    'SM_total_spikes': 10,\n",
    "    'noise': 100\n",
    "}\n",
    "\n",
    "scan_dict = {\n",
    "    'M': [1, 4, 8, 16, 32],\n",
    "    'N': [10, 20, 40, 80, 120],\n",
    "    'D': [11, 31, 51, 71, 101], \n",
    "    'num_SM_events': [2, 4, 8, 16, 32],\n",
    "    'SM_total_spikes': [3, 5, 10, 20, 50],\n",
    "    'noise': [0, 50, 100, 500, 1000]\n",
    "}\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_combinations = []\n",
    "for param_name, param_values in scan_dict.items():\n",
    "    for param_value in param_values:\n",
    "        params = default_params.copy()\n",
    "        params[param_name] = param_value\n",
    "        param_combinations.append(params)\n",
    "\n",
    "num_samples = len(param_combinations)\n",
    "results = []\n",
    "\n",
    "# Iterate through parameter combinations\n",
    "for idx, params in tqdm(enumerate(param_combinations)):\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_json(filename)\n",
    "        with open(filename, 'r') as results_file:\n",
    "            results = json.load(results_file)\n",
    "            \n",
    "    print(params)\n",
    "    A_dense, A_sparse, B_dense, B_sparse, K_dense, K_sparse = simulate_data.generate_synthetic_data(params)\n",
    "    \n",
    "    if len(A_sparse[0]) <= 2000: # and idx not in df['idx'].tolist():\n",
    "        start = time.time()\n",
    "        spike_trains = [SpikeTrain(A_sparse[1][A_sparse[0]==n] ,units= pq.ms, t_stop=params['T']) for n in range(params['N'])]\n",
    "        patterns = elephant.spade.spade(spike_trains, bin_size=pq.ms, winlen=params['D'], output_format='patterns')['patterns']\n",
    "        spade_patterns = fix_spade(patterns, params['D'])\n",
    "        win_size = (K_dense.shape[0],1+max([max(k[:,0]) for k in spade_patterns]))\n",
    "        spade_imgs = np.zeros((*win_size,len(spade_patterns)))\n",
    "        for p, pattern in enumerate(spade_patterns):\n",
    "            for (i,j) in pattern: \n",
    "                spade_imgs[j,i,p] = 1\n",
    "\n",
    "        SM_acc, cc = get_acc(K_dense,spade_imgs)\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        window_time = np.nan\n",
    "        cluster_time = np.nan\n",
    "        sequence_time = np.nan\n",
    "\n",
    "        result = {\n",
    "            'idx':idx,\n",
    "            'M':params['M'],\n",
    "            'N':params['N'],\n",
    "            'D':params['D'],\n",
    "            'T':params['T'],\n",
    "            'num_SM_events':params['num_SM_events'],\n",
    "            'SM_total_spikes':params['SM_total_spikes'],\n",
    "            'noise':params['noise'],\n",
    "            'window_time': window_time,\n",
    "            'cluster_time': cluster_time,\n",
    "            'sequence_time': sequence_time,\n",
    "            'total_time': end-start,\n",
    "            'total_spikes':len(A_sparse[1]),\n",
    "            'total_patterns':len(spade_patterns),\n",
    "            'SM_acc':SM_acc.tolist()\n",
    "        }\n",
    "    else:\n",
    "        result = {\n",
    "            'idx':idx,\n",
    "            'M':params['M'],\n",
    "            'N':params['N'],\n",
    "            'D':params['D'],\n",
    "            'T':params['T'],\n",
    "            'num_SM_events':params['num_SM_events'],\n",
    "            'SM_total_spikes':params['SM_total_spikes'],\n",
    "            'noise':params['noise'],\n",
    "            'window_time': np.nan,\n",
    "            'cluster_time': np.nan,\n",
    "            'sequence_time': np.nan,\n",
    "            'total_time': np.nan,\n",
    "            'total_spikes':len(A_sparse[1]),\n",
    "            'total_patterns':np.nan,\n",
    "            'SM_acc':[np.nan]\n",
    "        }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    with open(filename, 'w') as results_file:\n",
    "        json.dump(results, results_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618eb603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac9614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c62c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000021A3D62A7D0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"M\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbf5de04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        M         N         D   T  num_SM_events  \\\n",
      "M                1.000000 -0.019511 -0.003807 NaN      -0.022546   \n",
      "N               -0.019511  1.000000 -0.003488 NaN      -0.020657   \n",
      "D               -0.003807 -0.003488  1.000000 NaN      -0.004031   \n",
      "T                     NaN       NaN       NaN NaN            NaN   \n",
      "num_SM_events   -0.022546 -0.020657 -0.004031 NaN       1.000000   \n",
      "SM_total_spikes -0.024370 -0.022329 -0.004357 NaN      -0.025802   \n",
      "noise           -0.031629 -0.028979 -0.005655 NaN      -0.033487   \n",
      "window_time      0.331701 -0.062696  0.011927 NaN       0.448662   \n",
      "cluster_time     0.404064  0.059379 -0.059149 NaN       0.476124   \n",
      "sequence_time   -0.049144 -0.004694 -0.015947 NaN       0.010094   \n",
      "total_time       0.118995 -0.006469  0.026695 NaN       0.410689   \n",
      "total_patterns  -0.102824  0.030625 -0.003024 NaN      -0.030117   \n",
      "\n",
      "                 SM_total_spikes     noise  window_time  cluster_time  \\\n",
      "M                      -0.024370 -0.031629     0.331701      0.404064   \n",
      "N                      -0.022329 -0.028979    -0.062696      0.059379   \n",
      "D                      -0.004357 -0.005655     0.011927     -0.059149   \n",
      "T                            NaN       NaN          NaN           NaN   \n",
      "num_SM_events          -0.025802 -0.033487     0.448662      0.476124   \n",
      "SM_total_spikes         1.000000 -0.036196     0.759736      0.722242   \n",
      "noise                  -0.036196  1.000000     0.024079      0.087765   \n",
      "window_time             0.759736  0.024079     1.000000      0.963901   \n",
      "cluster_time            0.722242  0.087765     0.963901      1.000000   \n",
      "sequence_time           0.976225 -0.096067     0.757758      0.714504   \n",
      "total_time              0.860988 -0.024139     0.959040      0.924766   \n",
      "total_patterns          0.941443 -0.178031     0.632539      0.618530   \n",
      "\n",
      "                 sequence_time  total_time  total_patterns  \n",
      "M                    -0.049144    0.118995       -0.102824  \n",
      "N                    -0.004694   -0.006469        0.030625  \n",
      "D                    -0.015947    0.026695       -0.003024  \n",
      "T                          NaN         NaN             NaN  \n",
      "num_SM_events         0.010094    0.410689       -0.030117  \n",
      "SM_total_spikes       0.976225    0.860988        0.941443  \n",
      "noise                -0.096067   -0.024139       -0.178031  \n",
      "window_time           0.757758    0.959040        0.632539  \n",
      "cluster_time          0.714504    0.924766        0.618530  \n",
      "sequence_time         1.000000    0.876907        0.957976  \n",
      "total_time            0.876907    1.000000        0.780181  \n",
      "total_patterns        0.957976    0.780181        1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\AppData\\Local\\Temp\\ipykernel_20648\\2448198415.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_matrix = df.corr()\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
