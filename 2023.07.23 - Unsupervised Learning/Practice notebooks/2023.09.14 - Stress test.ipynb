{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a2fbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9be94178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(params):\n",
    "    '''\n",
    "    Synthetic Data Generation\n",
    "    '''\n",
    "    # Dense K: matrix of binary images of sizeNxDxM\n",
    "    # Sparse K: set of (delay d, neuron a, and pg b)\n",
    "\n",
    "    M,N,D,T,nrn_fr,pg_fr,background_noise_fr = params['M'], params['N'], params['D'], params['T'], params['nrn_fr'],params['pg_fr'],params['background_noise_fr'],    \n",
    "    '''\n",
    "    Synthetic Data Generation\n",
    "    '''\n",
    "    # Dense K: matrix of binary images of sizeNxDxM\n",
    "    # Sparse K: set of (delay d, neuron a, and pg b)\n",
    "\n",
    "    K_dense = np.random.rand(N,D,M)*1000\n",
    "    nrn_frs = np.zeros((M))\n",
    "    for m in range(M):\n",
    "        nrn_frs[m] = np.random.poisson(nrn_fr)\n",
    "        K_dense[:,:,m] = (K_dense[:,:,m] < nrn_frs[m]).astype('int')\n",
    "    K_sparse = np.where(K_dense)\n",
    "    K_sparse = (K_sparse[0],K_sparse[1],K_sparse[2]+1)\n",
    "\n",
    "\n",
    "    # dense B: the binary image of the occurrences of the spiking motif as a ( M x T) matrix\n",
    "    # spare B: set of all times t and pg's b\n",
    "    B_dense = np.random.rand(M,T)*1000\n",
    "    pg_frs = np.zeros((M))\n",
    "    for m in range(M):\n",
    "        pg_frs[m] = np.random.poisson(pg_fr)\n",
    "        B_dense[m,:] = (B_dense[m,:] < pg_frs[m]).astype('int')\n",
    "    B_sparse = np.where(B_dense)\n",
    "    B_sparse = (B_sparse[0]+1,B_sparse[1])# This way the first motif starts at index 1 instead of index 0\n",
    "\n",
    "    # now to make the full raster plot keeping the labels in-tact\n",
    "    # dense A: the layered binary images of all neuron spikes by PG ( N x T x M\n",
    "    A_dense = np.zeros((N,T+D,M+1))\n",
    "    A_dense[...,0] = np.random.rand(N,T+D)*1000\n",
    "    A_dense[...,0] = (A_dense[...,0] < background_noise_fr).astype('int')\n",
    "    for i in range(len(B_sparse[0])):\n",
    "        t = B_sparse[1][i]\n",
    "        b = B_sparse[0][i]\n",
    "        A_dense[:, t:t+D, b] += K_dense[...,b-1]\n",
    "\n",
    "    A_sparse = np.where(A_dense)\n",
    "    A_dense = np.sum(A_dense,axis=2)\n",
    "    A_dense[A_dense>1] = 1\n",
    "    return A_dense, A_sparse, B_dense, B_sparse, K_dense, K_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "867f603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_raster(T_labels, N_labels, window_dim = None):\n",
    "    '''\n",
    "    T_labels an array of spiketimes\n",
    "    N_labels corresponding array of neuron labels\n",
    "    window_dim is the size of the window to cluster the spikes\n",
    "    '''\n",
    "    print(f'Cleaning spikes...',end='\\r')\n",
    "    if window_dim == None:\n",
    "        window_dim = 100\n",
    "        \n",
    "    T_labels = np.round(T_labels).astype(int)\n",
    "    T_labels, N_labels = np.unique(np.array([T_labels,N_labels]),axis=1) # This removes any spikes that occur at the same neuron at the same time\n",
    "    N=max(N_labels)+1\n",
    "\n",
    "    print(f'Windowing... {len(T_labels)}')\n",
    "    windows = np.zeros((len(T_labels)),dtype='object')\n",
    "    for i,window_time in enumerate(T_labels):\n",
    "        condition = (T_labels > window_time-window_dim) & (T_labels < window_time + window_dim)\n",
    "        window = np.array([T_labels[condition]-window_time, N_labels[condition]]).T\n",
    "        window =  {tuple(row) for row in  window}\n",
    "        windows[i] = window\n",
    "\n",
    "        \n",
    "    # Set the cutoff value for clustering\n",
    "    cutoff = 0\n",
    "    lr = 0.01\n",
    "\n",
    "    max_iter=50\n",
    "    lr = 0.01\n",
    "    iter_ = 0\n",
    "\n",
    "    opt_cutoff = cutoff\n",
    "    max_seq_rep = 0\n",
    "    sim_mats = _get_sim_mats(windows, T_labels, N_labels)\n",
    "\n",
    "    while iter_ <= max_iter: # this is just a for loop...\n",
    "        clusters = _cluster_windows(cutoff, N_labels, sim_mats)\n",
    "        cluster_sq, _sq_counts, sublist_keys_filt = _check_seq(clusters, T_labels, N_labels)\n",
    "\n",
    "        if len(sublist_keys_filt) != 0:\n",
    "            max_ = np.max([len(k) for k in sublist_keys_filt])\n",
    "            if max_seq_rep < max_:\n",
    "                max_seq_rep = max_\n",
    "                opt_cutoff=cutoff\n",
    "\n",
    "        cutoff += lr\n",
    "        iter_ +=1\n",
    "\n",
    "\n",
    "        print(f'iter - {iter_/max_iter} | cutoff - {cutoff} | opt_cutoff - {opt_cutoff} | most_detections - {max_seq_rep}',end='\\r')\n",
    "\n",
    "    clusters = _cluster_windows(opt_cutoff, N_labels, sim_mats)\n",
    "    cluster_sq, sq_counts, sublist_keys_filt = _check_seq(clusters, T_labels, N_labels)\n",
    "        \n",
    "\n",
    "    ''' to get the timings'''\n",
    "\n",
    "    # Sort y according to x\n",
    "    sorted_indices = np.argsort(T_labels)\n",
    "    sorted_x = T_labels[sorted_indices]\n",
    "\n",
    "    all_times = []\n",
    "    all_labels = []\n",
    "    for key in sublist_keys_filt:\n",
    "        pattern_repetition_labels = np.zeros((len(cluster_sq[str(key)]),len(clusters)))\n",
    "        for i,k in enumerate(cluster_sq[str(key)]):\n",
    "            pattern_repetition_labels[i][clusters==k] = 1\n",
    "            pattern_repetition_labels[i] *= np.cumsum(pattern_repetition_labels[i])\n",
    "        pattern_repetition_labels = np.sum(pattern_repetition_labels,axis=0,dtype='int')\n",
    "        all_labels.append(pattern_repetition_labels)\n",
    "\n",
    "        sorted_y = pattern_repetition_labels[sorted_indices]\n",
    "        pattern_times = np.array([sorted_x[sorted_y==i][0] for i in range(1,max(pattern_repetition_labels)+1)])\n",
    "        all_times.append(pattern_times)\n",
    "\n",
    "    pattern_template = []\n",
    "    patterns = []\n",
    "    for i in range(len(all_times)):\n",
    "        pattern = []\n",
    "        pattern_template.append([])\n",
    "        for time in all_times[i]:\n",
    "            condition = (T_labels > time-window_dim*2) & (T_labels < time + window_dim*2)\n",
    "            pattern = [tuple(k) for k in np.array([T_labels[condition]-time, N_labels[condition]]).T] # creating a list of tuples\n",
    "            pattern_template[-1] += pattern # adds all points of each pattern to template_pattern\n",
    "            patterns.append(pattern)\n",
    "\n",
    "    for i,pattern in enumerate(pattern_template):\n",
    "        counts = [pattern.count(k) for k in pattern]\n",
    "        pattern_template[i] = np.array(pattern)[np.where(counts == np.max(counts))[0]]\n",
    "        pattern_template[i][:,0] -= min(pattern_template[i][:,0])\n",
    "        pattern_template[i] = np.unique(pattern_template[i],axis=0)\n",
    "    \n",
    "    if len(pattern_template) == 0:\n",
    "        return pattern_template, sublist_keys_filt, None\n",
    "    \n",
    "    win_size = (N,1+max([max(k[:,0]) for k in pattern_template]))\n",
    "    pattern_img = np.zeros((len(pattern_template),*win_size))\n",
    "    for p,pattern in enumerate(pattern_template):\n",
    "        for (i,j) in pattern:\n",
    "            pattern_img[p,j,i] = 1\n",
    "\n",
    "    return pattern_template, sublist_keys_filt, pattern_img\n",
    "\n",
    "def _get_sim_mats(windows, T_labels, N_labels):\n",
    "    intersect = lambda a,b : a[((a[:,None] == B).all(-1).any(1))]\n",
    "    sim_mats = np.zeros(N,dtype='object')\n",
    "    for n in np.unique(N_labels):\n",
    "        idc = np.where(N_labels==n)[0]\n",
    "        windows_n = windows[idc]\n",
    "        if len(windows_n) > 1:\n",
    "            x = np.zeros((len(windows_n),len(windows_n)))\n",
    "            for i in range(windows_n.shape[0]):\n",
    "                for j in range(windows_n.shape[0]):\n",
    "                    common_rows = windows_n[i].intersection(windows_n[j])\n",
    "                    num_identical_rows = len(common_rows)\n",
    "                    x[i,j] = len(common_rows)/min(len(windows_n[i]),len(windows_n[j]))\n",
    "            np.fill_diagonal(x,0)# make sure the diagonals are zero, this is important the more spikes there are...\n",
    "            sim_mats[n] = x-1 \n",
    "    return sim_mats\n",
    "\n",
    "def _cluster_windows(cutoff, N_labels, sim_mats):\n",
    "    clusters = np.zeros_like(N_labels)\n",
    "    for n in np.unique(N_labels):\n",
    "        idc = np.where(N_labels==n)[0]\n",
    "        if (type(sim_mats[n]) == np.ndarray) and (not np.all(sim_mats[n] == 0)):\n",
    "            l = max(clusters)+1\n",
    "            clusters[idc]= l+fcluster(linkage(sim_mats[n], method='complete'), cutoff, criterion='distance')\n",
    "    return clusters\n",
    "\n",
    "def _check_seq(clusters, T_labels, N_labels):\n",
    "\n",
    "    time_differences = []\n",
    "    cluster_sq = {}\n",
    "    for cluster in np.unique(clusters):\n",
    "        temp = list(np.diff(np.unique(T_labels[clusters == cluster])))\n",
    "        str_temp = str(temp)\n",
    "        time_differences.append(temp)\n",
    "        if str_temp in cluster_sq.keys():\n",
    "            cluster_sq[str_temp] = cluster_sq[str_temp] + [cluster]\n",
    "        else:\n",
    "            cluster_sq[str_temp] = [cluster]\n",
    "\n",
    "    # Convert the list of lists to a set of tuples to remove duplicates\n",
    "    unique_sublists_set = set(tuple(sublist) for sublist in time_differences if sublist)\n",
    "\n",
    "    # Convert the set of tuples back to a list of lists\n",
    "    unique_sublists = [list(sublist) for sublist in unique_sublists_set]\n",
    "\n",
    "    # Count the occurrences of each unique sublist in the original list\n",
    "    sublist_counts = Counter(tuple(sublist) for sublist in time_differences if sublist)\n",
    "\n",
    "    # Print the unique sublists and their respective counts\n",
    "    sq_counts = np.zeros(len(sublist_counts)) \n",
    "    for i,sublist in enumerate(unique_sublists):\n",
    "        count = sublist_counts[tuple(sublist)]\n",
    "        sq_counts[i] = count\n",
    "    #     print(f\"{sublist}: {count} occurrences\")\n",
    "    sublist_keys_np = np.array([list(key) for key in sublist_counts.keys()],dtype='object')\n",
    "    sublist_keys_filt = sublist_keys_np[np.array(list(sublist_counts.values())) >1] # only bother clustering repetitions that appear for more than one neuron\n",
    "    \n",
    "    return cluster_sq, sq_counts, sublist_keys_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ccf37a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "def get_acc(ground_truths,detected_patterns):\n",
    "    # Calculate cross-correlation matrix\n",
    "    cross_corr_matrix = np.zeros((ground_truths.shape[2], detected_patterns.shape[2]))\n",
    "    SM_acc = np.zeros((ground_truths.shape[2]))\n",
    "    \n",
    "    if len(detected_patterns == 0):\n",
    "        return SM_acc, cross_corr_matrix\n",
    "    \n",
    "    for ground_truths_idx in range(ground_truths.shape[2]):\n",
    "        for detected_patterns_idx in range(detected_patterns.shape[2]):\n",
    "            cross_corr = np.zeros((ground_truths.shape[1]+detected_patterns.shape[1]-1))\n",
    "            for n in range(ground_truths.shape[0]):\n",
    "                cross_corr += correlate(ground_truths[n, :, ground_truths_idx], detected_patterns[n, :, detected_patterns_idx], mode='full')\n",
    "            max_corr = np.max(cross_corr) / max(np.sum(ground_truths[...,ground_truths_idx]),np.sum(detected_patterns[...,detected_patterns_idx]))\n",
    "            cross_corr_matrix[ground_truths_idx, detected_patterns_idx] = max_corr\n",
    "#     print(cross_corr_matrix)\n",
    "#     print( np.sum(ground_truths[...,ground_truths_idx]))\n",
    "    SM_acc = np.max(cross_corr_matrix,axis=1)\n",
    "    return SM_acc, cross_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "8319fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "        # Define the number of random samples you want to take\n",
    "    num_samples = 5  # Adjust this based on your computational resources\n",
    "    \n",
    "    trials = 1\n",
    "    \n",
    "    # List to hold the results\n",
    "    results = []\n",
    "    \n",
    "    param_combinations = np.array(np.meshgrid(*scan_dict.values())).T.reshape(-1, len(scan_dict))\n",
    "    num_iterations = len(param_combinations)\n",
    "    \n",
    "    # Generate random indices for sampling\n",
    "    random_indices = random.sample(range(num_iterations), num_samples)\n",
    "    \n",
    "    # Iterate through parameter combinations\n",
    "    for idx in tqdm(random_indices):\n",
    "        for trial in range(0,trials):\n",
    "            seed=trial\n",
    "            np.random.seed(seed)\n",
    "            params = {key: int(val) for key, val in zip(scan_dict.keys(), param_combinations[idx])}\n",
    "\n",
    "            # Run your program here to generate performance results\n",
    "            print(\"Params:\", params)\n",
    "            print(\"Generating raster plot...\")\n",
    "            _, A_sparse, _, B_sparse, K_dense, K_sparse = generate_synthetic_data(params)\n",
    "            print(\"Clustering...\")\n",
    "            pattern_template, sublist_keys_filt, pattern_img = scan_raster(A_sparse[1],A_sparse[0],window_dim=params['D'])\n",
    "            if type(pattern_img) != np.ndarray:\n",
    "                performance_result = (0,0)\n",
    "            else:\n",
    "                pattern_img = np.transpose(pattern_img,axes=[1,2,0])\n",
    "                SM_acc, _ = get_acc(K_dense, pattern_img)\n",
    "                performance_result = (np.sum(SM_acc>0.8)/len(SM_acc), np.mean(SM_acc))\n",
    "\n",
    "            # Create a dictionary to store the result\n",
    "            result = {\n",
    "                'idc': idx,\n",
    "                'trial':trial,\n",
    "                'data':[A_sparse,K_sparse,B_sparse],\n",
    "                **params,  # Unpack the parameters as separate columns\n",
    "                'performance':performance_result\n",
    "            }\n",
    "            \n",
    "            print(performance_result)\n",
    "\n",
    "            # Append the result to the list\n",
    "            results.append(result)\n",
    "        # Write the entire list of results to a JSON file\n",
    "    with open('scan_stats.json', 'w') as results_file:\n",
    "        json.dump(results, results_file, indent=4)\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "102d9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model default parameters\n",
    "'''\n",
    "\n",
    "M = 4 # Number of Spiking motifs\n",
    "N = 20 # Number of input neurons\n",
    "D = 71 # temporal depth of receptive field\n",
    "T = 1000\n",
    "nrn_fr = 15 # hz\n",
    "pg_fr = 6 # hz\n",
    "background_noise_fr = 10 # h\n",
    "seed=41\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "25860de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'M':M,\n",
    "    'N':N,\n",
    "    'D':D,\n",
    "    'T':T,\n",
    "    'nrn_fr':nrn_fr,\n",
    "    'pg_fr':pg_fr,\n",
    "    'background_noise_fr':background_noise_fr,\n",
    "    'seed':seed\n",
    "}\n",
    "scan_dict = {\n",
    "    'M':[1,4,16,32,64],\n",
    "    'N':[5,30,60,100],\n",
    "    'D':[10,30,70,150],\n",
    "    'T':[500,1000,1500],\n",
    "    'nrn_fr':[5,10,15,20],\n",
    "    'pg_fr':[3,4,5,8,10,20],\n",
    "    'background_noise_fr':[0,1,2,5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "5d2b7139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'M': 16, 'N': 60, 'D': 30, 'T': 1000, 'nrn_fr': 15, 'pg_fr': 10, 'background_noise_fr': 5}\n",
      "Generating raster plot...\n",
      "Clustering...\n",
      "Cleaning spikes...\r",
      "Windowing... [   2    8    9 ... 1028 1029 1029]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[412], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m main()\n",
      "Cell \u001b[1;32mIn[409], line 28\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m _, A_sparse, _, B_sparse, K_dense, K_sparse \u001b[38;5;241m=\u001b[39m generate_synthetic_data(params)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClustering...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m pattern_template, sublist_keys_filt, pattern_img \u001b[38;5;241m=\u001b[39m scan_raster(A_sparse[\u001b[38;5;241m1\u001b[39m],A_sparse[\u001b[38;5;241m0\u001b[39m],window_dim\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(pattern_img) \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     30\u001b[0m     performance_result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[407], line 34\u001b[0m, in \u001b[0;36mscan_raster\u001b[1;34m(T_labels, N_labels, window_dim)\u001b[0m\n\u001b[0;32m     32\u001b[0m opt_cutoff \u001b[38;5;241m=\u001b[39m cutoff\n\u001b[0;32m     33\u001b[0m max_seq_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 34\u001b[0m sim_mats \u001b[38;5;241m=\u001b[39m _get_sim_mats(windows, T_labels, N_labels)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m iter_ \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_iter: \u001b[38;5;66;03m# this is just a for loop...\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m _cluster_windows(cutoff, N_labels, sim_mats)\n",
      "Cell \u001b[1;32mIn[407], line 118\u001b[0m, in \u001b[0;36m_get_sim_mats\u001b[1;34m(windows, T_labels, N_labels)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 x[i,j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_rows)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(windows_n[i]),\u001b[38;5;28mlen\u001b[39m(windows_n[j]))\n\u001b[0;32m    117\u001b[0m         np\u001b[38;5;241m.\u001b[39mfill_diagonal(x,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;66;03m# make sure the diagonals are zero, this is important the more spikes there are...\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m         sim_mats[n] \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sim_mats\n",
      "\u001b[1;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0c6f8a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[354], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(windows_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      2\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(windows_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 3\u001b[0m             common_rows \u001b[38;5;241m=\u001b[39m intersect(windows_n[i],windows_n[j])\n\u001b[0;32m      4\u001b[0m             num_identical_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_rows)\n\u001b[0;32m      5\u001b[0m             x[i,j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_rows)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(windows_n[i]),\u001b[38;5;28mlen\u001b[39m(windows_n[j]))\n",
      "Cell \u001b[1;32mIn[348], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(a, b)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m intersect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m a,b : a[((a[:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m==\u001b[39m B)\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39many(\u001b[38;5;241m1\u001b[39m))]\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      3\u001b[0m sim_mats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(N,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mysnn\\Lib\\site-packages\\numpy\\core\\_methods.py:61\u001b[0m, in \u001b[0;36m_all\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(windows_n.shape[0]):\n",
    "        for j in range(windows_n.shape[0]):\n",
    "            common_rows = intersect(windows_n[i],windows_n[j])\n",
    "            num_identical_rows = len(common_rows)\n",
    "            x[i,j] = len(common_rows)/min(len(windows_n[i]),len(windows_n[j]))\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window1 =  {tuple(row) for row in  window}\n",
    "window1 =  {tuple(row) for row in  window}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "f0c1fc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(T_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "57e52516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24,   45,   55, ..., 1095, 1114, 1125], dtype=int16)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_labels.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "4fab82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.835694551467896\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# T_labels,N_labels = A_sparse[1],A_sparse[0]\n",
    "# windows = np.zeros((len(T_labels)),dtype='object')\n",
    "# for i,window_time in enumerate(T_labels):\n",
    "#     condition = (T_labels > window_time-window_dim) & (T_labels < window_time + window_dim)\n",
    "#     window = np.array([T_labels[condition]-window_time, N_labels[condition]]).T\n",
    "#     window =  {tuple(row) for row in  window}\n",
    "#     windows[i] = window\n",
    "#     print(i/len(T_labels),end='\\r')\n",
    "windows.tolist()\n",
    "sim_mats = np.zeros(N,dtype='object')\n",
    "for n in [0]:#np.unique(N_labels):\n",
    "    idc = np.where(N_labels==n)[0]\n",
    "    \n",
    "    windows_n = windows[idc]\n",
    "    if len(windows_n) > 1:\n",
    "        x = np.zeros((len(windows_n),len(windows_n)))\n",
    "        for i in range(windows_n.shape[0]):\n",
    "            for j in range(windows_n.shape[0]):\n",
    "                common_rows = windows_n[i].intersection(windows_n[j])\n",
    "                num_identical_rows = len(common_rows)\n",
    "                x[i,j] = len(common_rows)/min(len(windows_n[i]),len(windows_n[j]))\n",
    "        np.fill_diagonal(x,0)# make sure the diagonals are zero, this is important the more spikes there are...\n",
    "        sim_mats[n] = x-1 \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5ca3d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384.950688838958745655\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "T_labels,N_labels = A_sparse[1],A_sparse[0]\n",
    "T_labels, N_labels = T_labels, N_labels\n",
    "windows = np.zeros((len(T_labels)),dtype='object')\n",
    "for i,window_time in enumerate(T_labels):\n",
    "    condition = (T_labels > window_time-window_dim) & (T_labels < window_time + window_dim)\n",
    "    window = np.array([T_labels[condition]-window_time, N_labels[condition]]).T\n",
    "    window =  {tuple(row) for row in  window}\n",
    "    windows[i] = window\n",
    "    print(i/len(T_labels),end='\\r')\n",
    "sim_mats = np.zeros(N,dtype='object')\n",
    "for n in [0]:#np.unique(N_labels):\n",
    "    idc = np.where(N_labels==n)[0]\n",
    "    \n",
    "    windows_n = windows[idc]\n",
    "    if len(windows_n) > 1:\n",
    "        x = np.zeros((len(windows_n),len(windows_n)))\n",
    "        for i in range(windows_n.shape[0]):\n",
    "            for j in range(windows_n.shape[0]):\n",
    "                common_rows = windows_n[i].intersection(windows_n[j])\n",
    "                num_identical_rows = len(common_rows)\n",
    "                x[i,j] = len(common_rows)/min(len(windows_n[i]),len(windows_n[j]))\n",
    "        np.fill_diagonal(x,0)# make sure the diagonals are zero, this is important the more spikes there are...\n",
    "        sim_mats[n] = x-1 \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "bed09e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.30270743370056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "T_labels,N_labels = A_sparse[1],A_sparse[0]\n",
    "T_labels, N_labels = T_labels[:1000], N_labels[:1000]\n",
    "windows = np.zeros((len(T_labels)),dtype='object')\n",
    "for i,window_time in enumerate(T_labels):\n",
    "    condition = (T_labels > window_time-window_dim) & (T_labels < window_time + window_dim)\n",
    "    window = np.array([T_labels[condition]-window_time, N_labels[condition]]).T\n",
    "    windows[i] = window\n",
    "intersect = lambda a,b : a[((a[:,None] == B).all(-1).any(1))]\n",
    "sim_mats = np.zeros(N,dtype='object')\n",
    "for n in [0]:#np.unique(N_labels):\n",
    "    idc = np.where(N_labels==n)[0]\n",
    "    windows_n = windows[idc]\n",
    "    if len(windows_n) > 1:\n",
    "        x = np.zeros((len(windows_n),len(windows_n)))\n",
    "        for i in range(windows_n.shape[0]):\n",
    "            for j in range(windows_n.shape[0]):\n",
    "                common_rows = intersect(windows_n[i],windows_n[j])\n",
    "                num_identical_rows = len(common_rows)\n",
    "                x[i,j] = len(common_rows)/min(len(windows_n[i]),len(windows_n[j]))\n",
    "        np.fill_diagonal(x,0)# make sure the diagonals are zero, this is important the more spikes there are...\n",
    "        sim_mats[n] = x-1 \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "bd8f36bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [ 31,   0],\n",
       "       [ 77,   0],\n",
       "       [ 92,   0],\n",
       "       [ 98,   0],\n",
       "       [-12,   2],\n",
       "       [ 77,   3],\n",
       "       [ 95,   3],\n",
       "       [ 95,   3],\n",
       "       [ 98,   3],\n",
       "       [ 99,   3],\n",
       "       [ 88,   4]], dtype=int64)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = windows_n[0]\n",
    "B = windows_n[1]\n",
    "intersect = lambda a,b : a[((a[:,None] == B).all(-1).any(1))]\n",
    "intersect(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "44ab539d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  21,  31,  43,  52,  60,  66,  67,  77,  84,  90,  92,  93,\n",
       "         94,  98,  22,  23,  35,  42,  47,  62,  74,  93,  97,  99, -12,\n",
       "          9,  22,  35,  47,  48,  70,  81,  86,  87,  96,  96,  26,  33,\n",
       "         45,  49,  57,  58,  61,  73,  77,  84,  85,  95,  95,  97,  98,\n",
       "         99,  -6,   3,  43,  54,  62,  72,  84,  88,  90],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   3,   3,\n",
       "          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
       "          3,   4,   4,   4,   4,   4,   4,   4,   4,   4]], dtype=int64)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "d37057af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-12,   0,  21,  22,  26,  31,  33,  45,  49,  52,  60,  66,  67,\n",
       "         72,  73,  74,  77,  81,  86,  87,  88,  90,  92,  95,  97,  98,\n",
       "         99], dtype=int64),\n",
       " array([25,  0,  1, 15, 37,  2, 38, 39, 40,  4,  5,  6,  7, 58, 44, 21,  8,\n",
       "        32, 33, 34, 60, 10, 11, 48, 23, 14, 24], dtype=int64),\n",
       " array([36,  1, 21,  3, 22,  4, 75,  6, 41, 54, 42, 44, 79, 12, 13, 58, 14,\n",
       "        65, 30, 31, 32, 33, 15, 69, 16, 17, 71], dtype=int64))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(A.T[0],B.T[0],return_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "964ef061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=int64),\n",
       " array([ 0, 15, 25, 37, 53], dtype=int64),\n",
       " array([ 0, 18, 35, 47, 72], dtype=int64))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(A.T[1],B.T[1],return_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "7fb5c9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15, 25, 37], dtype=int64)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idc1 = np.intersect1d(A.T[0],B.T[0],return_indices=True)[1]\n",
    "idc2 = np.intersect1d(A.T[1],B.T[1],return_indices=True)[1]\n",
    "idc3 = np.intersect1d(idc1, idc2)\n",
    "idc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "96cc8885",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[365], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(windows_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(windows_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 11\u001b[0m         common_rows \u001b[38;5;241m=\u001b[39m windows_n[i]\u001b[38;5;241m.\u001b[39mintersection(windows_n[j])\n\u001b[0;32m     12\u001b[0m         num_identical_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_rows)\n\u001b[0;32m     13\u001b[0m         x[i,j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_rows)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(windows_n[i]),\u001b[38;5;28mlen\u001b[39m(windows_n[j]))\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "intersect = lambda a,b : a[((a[:,None] == B).all(-1).any(1))]\n",
    "start = time.time()\n",
    "sim_mats = np.zeros(N,dtype='object')\n",
    "for n in [0]:#np.unique(N_labels):\n",
    "    idc = np.where(N_labels==n)[0]\n",
    "    windows_n = windowsset[0]\n",
    "    if len(windows_n) > 1:\n",
    "        x = np.zeros((len(windows_n),len(windows_n)))\n",
    "        for i in range(windows_n.shape[0]):\n",
    "            for j in range(windows_n.shape[0]):\n",
    "                common_rows = windows_n[i].intersection(windows_n[j])\n",
    "                num_identical_rows = len(common_rows)\n",
    "                x[i,j] = len(common_rows)/min(len(windows_n[i]),len(windows_n[j]))\n",
    "        np.fill_diagonal(x,0)# make sure the diagonals are zero, this is important the more spikes there are...\n",
    "        sim_mats[n] = x-1 \n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "886ef5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowing... 22437\n",
      "1.0\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'intersection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[227], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m opt_cutoff \u001b[38;5;241m=\u001b[39m cutoff\n\u001b[0;32m     26\u001b[0m max_seq_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 27\u001b[0m sim_mats \u001b[38;5;241m=\u001b[39m _get_sim_mats(windows, T_labels, N_labels)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m iter_ \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_iter: \u001b[38;5;66;03m# this is just a for loop...\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m _cluster_windows(cutoff, N_labels, sim_mats)\n",
      "Cell \u001b[1;32mIn[163], line 111\u001b[0m, in \u001b[0;36m_get_sim_mats\u001b[1;34m(windows, T_labels, N_labels)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(windows_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(windows_n\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 111\u001b[0m         common_rows \u001b[38;5;241m=\u001b[39m windows_n[i]\u001b[38;5;241m.\u001b[39mintersection(windows_n[j])\n\u001b[0;32m    112\u001b[0m         num_identical_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_rows)\n\u001b[0;32m    113\u001b[0m         x[i,j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_rows)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(windows_n[i]),\u001b[38;5;28mlen\u001b[39m(windows_n[j]))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'intersection'"
     ]
    }
   ],
   "source": [
    "if window_dim == None:\n",
    "    window_dim = 100\n",
    "\n",
    "T_labels = np.round(T_labels).astype(int)\n",
    "T_labels, N_labels = np.unique(np.array([T_labels,N_labels]),axis=1) # This removes any spikes that occur at the same neuron at the same time\n",
    "N=max(N_labels)+1\n",
    "\n",
    "print(f'Windowing... {len(T_labels)}')\n",
    "windows = np.zeros((len(T_labels)),dtype='object')\n",
    "for i,window_time in enumerate(T_labels):\n",
    "    condition = (T_labels > window_time-window_dim) & (T_labels < window_time + window_dim)\n",
    "    window = np.array([T_labels[condition]-window_time, N_labels[condition]]).T\n",
    "    window =  {tuple(row) for row in  window}\n",
    "    windows[i] = window\n",
    "    print(f'{np.round(i/len(T_labels),1)}',end='\\r')\n",
    "\n",
    "\n",
    "# Set the cutoff value for clustering\n",
    "cutoff = 0\n",
    "lr = 0.01\n",
    "\n",
    "max_iter=50\n",
    "lr = 0.01\n",
    "iter_ = 0\n",
    "\n",
    "opt_cutoff = cutoff\n",
    "max_seq_rep = 0\n",
    "sim_mats = _get_sim_mats(windows, T_labels, N_labels)\n",
    "\n",
    "while iter_ <= max_iter: # this is just a for loop...\n",
    "    clusters = _cluster_windows(cutoff, N_labels, sim_mats)\n",
    "    cluster_sq, _sq_counts, sublist_keys_filt = _check_seq(clusters, T_labels, N_labels)\n",
    "\n",
    "    if len(sublist_keys_filt) != 0:\n",
    "        max_ = np.max([len(k) for k in sublist_keys_filt])\n",
    "        if max_seq_rep < max_:\n",
    "            max_seq_rep = max_\n",
    "            opt_cutoff=cutoff\n",
    "\n",
    "    cutoff += lr\n",
    "    iter_ +=1\n",
    "\n",
    "\n",
    "    print(f'iter - {iter_/max_iter} | cutoff - {cutoff} | opt_cutoff - {opt_cutoff} | most_detections - {max_seq_rep}',end='\\r')\n",
    "\n",
    "clusters = _cluster_windows(opt_cutoff, N_labels, sim_mats)\n",
    "cluster_sq, sq_counts, sublist_keys_filt = _check_seq(clusters, T_labels, N_labels)\n",
    "\n",
    "\n",
    "''' to get the timings'''\n",
    "\n",
    "# Sort y according to x\n",
    "sorted_indices = np.argsort(T_labels)\n",
    "sorted_x = T_labels[sorted_indices]\n",
    "\n",
    "all_times = []\n",
    "all_labels = []\n",
    "for key in sublist_keys_filt:\n",
    "    pattern_repetition_labels = np.zeros((len(cluster_sq[str(key)]),len(clusters)))\n",
    "    for i,k in enumerate(cluster_sq[str(key)]):\n",
    "        pattern_repetition_labels[i][clusters==k] = 1\n",
    "        pattern_repetition_labels[i] *= np.cumsum(pattern_repetition_labels[i])\n",
    "    pattern_repetition_labels = np.sum(pattern_repetition_labels,axis=0,dtype='int')\n",
    "    all_labels.append(pattern_repetition_labels)\n",
    "\n",
    "    sorted_y = pattern_repetition_labels[sorted_indices]\n",
    "    pattern_times = np.array([sorted_x[sorted_y==i][0] for i in range(1,max(pattern_repetition_labels)+1)])\n",
    "    all_times.append(pattern_times)\n",
    "\n",
    "pattern_template = []\n",
    "patterns = []\n",
    "for i in range(len(all_times)):\n",
    "    pattern = []\n",
    "    pattern_template.append([])\n",
    "    for time in all_times[i]:\n",
    "        condition = (T_labels > time-window_dim*2) & (T_labels < time + window_dim*2)\n",
    "        pattern = [tuple(k) for k in np.array([T_labels[condition]-time, N_labels[condition]]).T] # creating a list of tuples\n",
    "        pattern_template[-1] += pattern # adds all points of each pattern to template_pattern\n",
    "        patterns.append(pattern)\n",
    "\n",
    "for i,pattern in enumerate(pattern_template):\n",
    "    counts = [pattern.count(k) for k in pattern]\n",
    "    pattern_template[i] = np.array(pattern)[np.where(counts == np.max(counts))[0]]\n",
    "    pattern_template[i][:,0] -= min(pattern_template[i][:,0])\n",
    "    pattern_template[i] = np.unique(pattern_template[i],axis=0)\n",
    "\n",
    "if len(pattern_template) == 0:\n",
    "    break\n",
    "\n",
    "win_size = (N,1+max([max(k[:,0]) for k in pattern_template]))\n",
    "pattern_img = np.zeros((len(pattern_template),*win_size))\n",
    "for p,pattern in enumerate(pattern_template):\n",
    "    for (i,j) in pattern:\n",
    "        pattern_img[p,j,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "17746196",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 99 is out of bounds for axis 0 with size 60",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sim_mats[n]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 99 is out of bounds for axis 0 with size 60"
     ]
    }
   ],
   "source": [
    "sim_mats[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1607ad13",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(N_labels):\n\u001b[0;32m      3\u001b[0m     idc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(N_labels\u001b[38;5;241m==\u001b[39mn)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(sim_mats[n]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(sim_mats[n] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m      5\u001b[0m         l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(clusters)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m         clusters[idc]\u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m+\u001b[39mfcluster(linkage(sim_mats[n], method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m'\u001b[39m), cutoff, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "clusters = np.zeros_like(N_labels)\n",
    "for n in np.unique(N_labels):\n",
    "    idc = np.where(N_labels==n)[0]\n",
    "    if (len(sim_mats[n]) > 0) and (not np.all(sim_mats[n] == 0)):\n",
    "        l = max(clusters)+1\n",
    "        clusters[idc]= l+fcluster(linkage(sim_mats[n], method='complete'), cutoff, criterion='distance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f55b33c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.96428571, -0.98214286, -0.98214286, -0.96428571,\n",
       "        -0.94642857, -0.96428571, -0.98214286, -0.98214286, -0.98214286,\n",
       "        -0.625     , -0.98214286, -0.98214286],\n",
       "       [-0.96428571, -1.        , -0.96062992, -0.992     , -0.82075472,\n",
       "        -0.98181818, -0.85      , -0.79545455, -0.98648649, -0.98245614,\n",
       "        -0.96875   , -0.84375   , -0.984375  ],\n",
       "       [-0.98214286, -0.96062992, -1.        , -0.832     , -0.96226415,\n",
       "        -0.8       , -0.95833333, -0.97727273, -0.97297297, -0.59649123,\n",
       "        -0.82677165, -0.96850394, -0.96062992],\n",
       "       [-0.98214286, -0.992     , -0.832     , -1.        , -0.99056604,\n",
       "        -0.79090909, -0.975     , -0.98863636, -0.97297297, -0.63157895,\n",
       "        -0.824     , -0.992     , -0.96      ],\n",
       "       [-0.96428571, -0.82075472, -0.96226415, -0.99056604, -1.        ,\n",
       "        -0.97169811, -0.82075472, -0.79545455, -0.97297297, -0.96491228,\n",
       "        -0.97169811, -0.81132075, -0.98113208],\n",
       "       [-0.94642857, -0.98181818, -0.8       , -0.79090909, -0.97169811,\n",
       "        -1.        , -0.97272727, -0.97727273, -0.98648649, -0.63157895,\n",
       "        -0.77272727, -0.99090909, -0.95454545],\n",
       "       [-0.96428571, -0.85      , -0.95833333, -0.975     , -0.82075472,\n",
       "        -0.97272727, -1.        , -0.78409091, -0.98648649, -0.96491228,\n",
       "        -0.975     , -0.83333333, -0.98333333],\n",
       "       [-0.98214286, -0.79545455, -0.97727273, -0.98863636, -0.79545455,\n",
       "        -0.97727273, -0.78409091, -1.        , -0.98648649, -0.98245614,\n",
       "        -0.97727273, -0.79545455, -0.96590909],\n",
       "       [-0.98214286, -0.98648649, -0.97297297, -0.97297297, -0.97297297,\n",
       "        -0.98648649, -0.98648649, -0.98648649, -1.        , -0.98245614,\n",
       "        -0.97297297, -0.98648649, -0.98648649],\n",
       "       [-0.98214286, -0.98245614, -0.59649123, -0.63157895, -0.96491228,\n",
       "        -0.63157895, -0.96491228, -0.98245614, -0.98245614, -1.        ,\n",
       "        -0.63157895, -0.98245614, -0.94736842],\n",
       "       [-0.625     , -0.96875   , -0.82677165, -0.824     , -0.97169811,\n",
       "        -0.77272727, -0.975     , -0.97727273, -0.97297297, -0.63157895,\n",
       "        -1.        , -0.984375  , -0.9765625 ],\n",
       "       [-0.98214286, -0.84375   , -0.96850394, -0.992     , -0.81132075,\n",
       "        -0.99090909, -0.83333333, -0.79545455, -0.98648649, -0.98245614,\n",
       "        -0.984375  , -1.        , -0.984375  ],\n",
       "       [-0.98214286, -0.984375  , -0.96062992, -0.96      , -0.98113208,\n",
       "        -0.95454545, -0.98333333, -0.96590909, -0.98648649, -0.94736842,\n",
       "        -0.9765625 , -0.984375  , -1.        ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mats[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "010d099d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sim_mats[20]) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a3874f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sim_mats[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "30ca8fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_labels[N_labels==n].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6a49773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = sim_mats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "07027898",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mats = np.zeros(N,dtype='object')\n",
    "for n in np.unique(N_labels):\n",
    "    idc = np.where(N_labels==n)[0]\n",
    "    windows_n = windows[idc]\n",
    "    if len(windows_n) > 1:\n",
    "        x = np.zeros((len(windows_n),len(windows_n)))\n",
    "        for i in range(windows_n.shape[0]):\n",
    "            for j in range(windows_n.shape[0]):\n",
    "                common_rows = windows_n[i].intersection(windows_n[j])\n",
    "                num_identical_rows = len(common_rows)\n",
    "                x[i,j] = len(common_rows)/min(len(windows_n[i]),len(windows_n[j]))\n",
    "        np.fill_diagonal(x,0)# make sure the diagonals are zero, this is important the more spikes there are...\n",
    "        sim_mats[n] = x-1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a86575cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mats[n].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6679d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
